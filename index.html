<!DOCTYPE html>
<html>
<head>
  <meta content="text/html;charset=utf-8" http-equiv="Content-Type">
  <meta content="utf-8" http-equiv="encoding">
  <meta name="description" content="MS student at Stanford, research assistant at Stanford AI Lab, computer vision at Tesla."/>
  <title>Vincent Sunn Chen</title>
  <link href="https://fonts.googleapis.com/css?family=Muli:200,300,400|Open+Sans" rel="stylesheet">

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.8/css/brands.css" integrity="sha384-IiIL1/ODJBRTrDTFk/pW8j0DUI5/z9m1KYsTm/RjZTNV8RHLGZXkUDwgRRbbQ+Jh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.8/css/fontawesome.css" integrity="sha384-q3jl8XQu1OpdLgGFvNRnPdj5VIlCvgsDQTQB6owSOHWlAurxul7f+JpUOVdAiJ5P" crossorigin="anonymous">
  <link href="main.min.css" rel="stylesheet" />
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-96755925-1', 'auto');
  ga('send', 'pageview');

</script>

<body class="container">
  <!-- <div class="container"> -->
    <div class='header'>
      <a href="http://twitter.com/vincentsunnchen"><i class='fab fa-twitter'></i> vincentsunnchen</a>
      <a href="http://vincentsc.com/blog">/blog</a>
      <a href="https://github.com/vincentschen"><i class='fab fa-github'></i> vincentschen</a> </a>
    </div>

    <img src="head.jpg">

    <h1>vincent sunn chen</h1>
    <div class='email'> vincentsc [at] cs [dot] stanford [dot] edu</div>

    <div>
      <p>I'm a MS/BS student at Stanford with a concentration in machine learning and a minor in creative writing.
        I'm interested in <a href="http://dawn.cs.stanford.edu/2017/07/16/weak-supervision/">shaping datasets</a> to make machine deep learning more accesible to domain experts in fields like medical imaging.
      </p>

      <p>I'm currently a research assistant in the Stanford AI Lab with <a href="https://cs.stanford.edu/people/chrismre/">Chris Ré</a>'s group.
        Most recently, I've trained neural networks on the <a href="https://www.tesla.com/autopilot">Autopilot vision team at Tesla</a>.
        In the past, I worked at <a href="https://siftscience.com/">Sift Science</a> to fight fraud with machine learning, <a href="https://www.xbox.com/">Xbox</a> to build VR experiences, and <a href="https://emguidance.com/">EMGuidance</a> to build point-of-care healthcare tools.
        At Stanford, I had a lot of fun <a href="https://www.stanforddaily.com/treehacks-2016/">co-directing</a> <a href="https://www.treehacks.com/">TreeHacks</a>, the university's flagship, international hackathon.</a>
      </p>

      <p>I also love <a href="https://www.goodreads.com/user/show/45853018-vincent-chen">reading</a>, <a href="https://blog.ycombinator.com/category/paths/">writing</a>, and <a href="https://www.flickr.com/photos/vincentschen/">photography</a>!</p>
    </div>
    <h2>teaching</h2>
    <div class="projects">
      <section>
        <h3>CS231N: Convolutional Neural Networks for Visual Recognition</h3>
        <p>Teaching Assistant, <a href="http://cs231n.stanford.edu/">Spring 2018</a></p>
        <p>Hosted office hours, advised student projects, and led discussion sections on <a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_ds02.pdf">backpropogation</a> and <a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_ds07.pdf">weak supervision</a>.</p>
      </section>
    </div>

    <h2>projects and papers</h2>
    <div class="projects">
      <h3>Weakly supervised classification of rare aortic valve malformations using unlabeled cardiac MRI sequences</h3>
      <p>Jason A Fries, Paroma Varma, <span class="me">Vincent S Chen</span>, Ke Xiao, Heliodoro Tejeda, Priyanka Saha, Jared Dunnmon, Henry Chubb, Shiraz Maskatia, Madalina Fiterau, Scott Delp, Euan Ashley, Christopher Ré, James Priest</p>
      <p><a href="https://www.biorxiv.org/content/early/2018/08/22/339630">BioArxiv Preprint 2018.</a></p>
      
      <section>
        <h3>Automated Training Set Generation for Aortic Valve Classification</h3>
        <p><span class="me">Vincent Chen</span>, Paroma Varma, Madalina Fiterau, James Priest and Christopher Ré.</p>
        <p>
           <a href="https://ml4health.github.io/2017/pages/posters.html">Neural Information Processing Systems 2017, ML4H Workshop.</a>
          [<a href="pdf/nips17_ml4h.pdf">pdf</a>] [<a href="pdf/bav_poster.pdf">poster</a>]
        </p>
        <p>Using weak-supervision, we learn probabilistic training labels for aortic valve MRIs.</p>
      </section>

      <section>
        <h3>Generating Training Labels for Cardiac Phase-Contrast MRI Images</h3>
        <p><span class="me">Vincent Chen</span>, Paroma Varma, Madalina Fiterau, James Priest and Christopher Ré.</p>
        <p>
          <a href="https://sites.google.com/view/med-nips-2017/abstracts">Neural Information Processing Systems 2017, Medical Imaging Workshop.</a>
          [<a href="pdf/nips17_med-nips.pdf">pdf</a>]
        </p>
      </section>

      <section>
        <h3>Predicting Wealth in NYC from FourSquare Check-ins</h3>
        <p><span class="me">Vincent Chen</span>*, Dan Yu*.</p>
        <p>
          <a href="http://cs229.stanford.edu/">CS229: Machine Learning.</a> 
          [<a href="http://vincentsc.com/blog/2018/01/05/predicting-wealth-in-nyc.html">blog</a>] [<a href="pdf/foursquare.pdf">pdf</a>] [<a href="https://github.com/vincentschen/predicting-nyc-demographics">code</a>]
        </p>
        <p>We develop a new method to predict demographics based on FourSquare data by engineering features based on check-ins mapped to U.S. census tracts.
      </section>

      <section>
        <h3>Class-conditional Superresolution with GANs</h3>
        <p><span class="me">Vincent Chen</span>*, Liezl Puzon*, Christina Wadsworth*.</p>
        <p>
          <a href="http://cs231n.github.io">CS231N: ConvNets for Visual Recognition.</a>
          [<a href="http://cs231n.stanford.edu/reports/2017/pdfs/314.pdf">pdf</a>] [<a href="http://cs231n.stanford.edu/reports/2017/posters/314.pdf">poster</a>] [<a href="https://github.com/vincentschen/cgan-superres">code</a>]
        </p>
        <p>We propose several methods to introduce auxiliary, conditional information into generative adversarial networks (GANs) that produce super-resolution results that better tuned to the human eye.</p>
      </section>

      <section>
        <h3>Sequence-to-Sequence Text Summarization</h3>
        <p><span class="me">Vincent Chen</span>*, Liezl Puzon*, Eduardo Torres Montaño*. Advisor: Danqi Chen.</p>
        <p>
          <a href="http://web.stanford.edu/class/cs224n/">CS224N: Natural Language Processing with Deep Learning.</a>
          [<a href="pdf/summarization.pdf">pdf</a>]
        </p>
        <p>We implement several approaches for sequence-to-sequence summarization on the CNN/DailyMail dataset using attention mechanisms and pointer networks.</p>
      </section>

  <!-- </div> -->
</body>
</html>
